{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60128d87",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "273fe26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea0d89",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92f4aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e928997a",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32a28247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 1.7406 - accuracy: 0.5251 - val_loss: 1.0843 - val_accuracy: 0.6880\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.9803 - accuracy: 0.7272 - val_loss: 0.8565 - val_accuracy: 0.7527\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.8063 - accuracy: 0.7716 - val_loss: 0.7599 - val_accuracy: 0.7803\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.7025 - accuracy: 0.7967 - val_loss: 0.6627 - val_accuracy: 0.8033\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.6239 - accuracy: 0.8160 - val_loss: 0.5785 - val_accuracy: 0.8285\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5694 - accuracy: 0.8298 - val_loss: 0.5484 - val_accuracy: 0.8347\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.5173 - accuracy: 0.8407 - val_loss: 0.5053 - val_accuracy: 0.8462\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.8552 - val_loss: 0.4497 - val_accuracy: 0.8622\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4355 - accuracy: 0.8652 - val_loss: 0.4316 - val_accuracy: 0.8742\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 1ms/step - loss: 0.4071 - accuracy: 0.8723 - val_loss: 0.4187 - val_accuracy: 0.8765\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8765\n",
      "Test Accuracy: 0.8765000104904175\n"
     ]
    }
   ],
   "source": [
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606d39a",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3be74606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[1.2479063e-07 9.0228980e-03 2.5608984e-03 3.8127039e-02 9.0218574e-01\n",
      "  1.2613864e-03 1.9622834e-03 1.2377443e-02 5.2196177e-05 4.3947635e-05\n",
      "  4.6288045e-03 1.0783932e-03 7.3442425e-07 6.8899344e-09 3.9265942e-05\n",
      "  2.6099769e-05 7.3015349e-06 4.7566329e-05 2.4900353e-02 3.5393008e-04\n",
      "  9.5273035e-06 1.8815977e-07 2.7686580e-08 1.1297720e-03 1.3588445e-06\n",
      "  1.8261290e-04]]\n",
      "The predicted class is: 4\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "import numpy as np\n",
    "new_data = np.array([4, 7, 5, 5, 4, 6, 7, 3, 7, 11, 8, 9, 3, 8, 4, 8]).reshape(1, -1)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_data)\n",
    "print(predictions)\n",
    "# Display the predictions\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'The predicted class is: {predicted_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "684f3f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 4, which corresponds to the letter: E\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Display the predicted class using the mapping\n",
    "predicted_letter = class_mapping[predicted_class]\n",
    "print(f'The predicted class is: {predicted_class}, which corresponds to the letter: {predicted_letter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44001aa",
   "metadata": {},
   "source": [
    "## Dynamic Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b7c1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter values for the 17 features separated by commas: 4, 7, 5, 5, 4, 6, 7, 3, 7, 11, 8, 9, 3, 8, 4, 8\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "\n",
      "The predicted class is: 4 i.e. E\n"
     ]
    }
   ],
   "source": [
    "#dummy = 4, 7, 5, 5, 4, 6, 7, 3, 7, 11, 8, 9, 3, 8, 4, 8\n",
    "\n",
    "# Take input from the user\n",
    "user_input = input(\"Enter values for the 17 features separated by commas: \")\n",
    "user_input_list = [int(x) for x in user_input.split(',')]\n",
    "\n",
    "# Convert the user input to a NumPy array\n",
    "new_data = np.array(user_input_list).reshape(1, -1)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_data)\n",
    "#print(predictions)\n",
    "# Display the predictions\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'\\nThe predicted class is: {predicted_class} i.e. {class_mapping[predicted_class]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
